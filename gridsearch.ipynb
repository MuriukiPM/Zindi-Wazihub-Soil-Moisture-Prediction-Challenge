{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":"#!/usr/bin/python3\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom libs import utils\n\nfrom tempfile import mkdtemp\nfrom shutil import rmtree\n\nfrom sklearn.svm import SVR\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import GridSearchCV, TimeSeriesSplit\nimport joblib\n\ndef main():\n\n    train_df = pd.read_csv(\"data/Train.csv\", header=0)# ignore the first row of the CSV file.\n    cxt_maize_df = pd.read_csv(\"data/Context_Data_Maize.csv\", header=0)\n    cxt_peanuts_df = pd.read_csv(\"data/Context_Data_Peanuts.csv\", header=0)\n\n    train_df['datetime'] = pd.to_datetime(train_df['timestamp']) #to datetime\n    train_df['time_of_day'] = train_df['datetime'].apply(lambda x: x.hour) #some properties\n    train_df['month'] = train_df['datetime'].apply(lambda x: x.month)\n    train_df['week_of_year'] = train_df['datetime'].apply(lambda x: x.weekofyear)\n    train_df['date'] = train_df['datetime'].apply(lambda x: x.date()) #to datetime.date\n    train_df = train_df.set_index('datetime')\n    cxt_maize_df['date'] = pd.to_datetime(cxt_maize_df['Date'],format=\"%d-%b\")\n    cxt_maize_df['date'] = cxt_maize_df['date'].apply(lambda x: (x + pd.offsets.DateOffset(year=2019)).date()) #to datetime.date\n    cxt_peanuts_df['date'] = pd.to_datetime(cxt_peanuts_df['Date'],format=\"%d-%b\")\n    cxt_peanuts_df['date'] = cxt_peanuts_df['date'].apply(lambda x: (x + pd.offsets.DateOffset(year=2019)).date()) #to datetime.date\n\n    humidity_field1 = train_df[['Soil humidity 1']]\n    humidity_field2 = train_df[['Soil humidity 2']]\n    humidity_field3 = train_df[['Soil humidity 3']]\n    humidity_field4 = train_df[['Soil humidity 4']]\n    humidity_field2.loc[\n        '2019-05-25 07:45:00':'2019-05-31 09:20:00'\n        ].loc[\n            ~pd.isna(humidity_field2['Soil humidity 2']),'Soil humidity 2'] = np.nan\n    humidity_field4.loc[\n        '2019-05-25 07:45:00':'2019-05-31 09:20:00'\n        ].loc[\n            ~pd.isna(humidity_field4['Soil humidity 4']),'Soil humidity 4'] = np.nan\n    humidity_field1.loc[\n        '2019-03-25 22:50:00':'2019-05-31 09:20:00'\n        ].loc[\n            ~pd.isna(humidity_field1['Soil humidity 1']),'Soil humidity 1'] = np.nan\n    humidity_field3.loc[\n        '2019-04-19 20:15:00':'2019-05-31 09:20:00'\n        ].loc[\n            ~pd.isna(humidity_field3['Soil humidity 3']),'Soil humidity 3'] = np.nan\n    train_df['Soil humidity 1'] = humidity_field1\n    train_df['Soil humidity 2'] = humidity_field2\n    train_df['Soil humidity 3'] = humidity_field3\n    train_df['Soil humidity 4'] = humidity_field4\n    train_df.dropna(subset=['Soil humidity 2'], inplace=True)\n    humidity_field2 = train_df[['Soil humidity 2']]\n\n    # perform train/test split\n    cutoff_field2 = '2019-05-20'\n    target_field2 = 'Soil humidity 2'\n    df_train, df_test, y_train, y_test = utils.ts_train_test_split(train_df, cutoff_field2, target_field2)\n\n    #rmtree(cachedir)\n    cachedir = mkdtemp() #creates a temporary directory\n\n    cols = ['Air temperature (C)',\n       'Air humidity (%)', 'Pressure (KPa)', 'Wind speed (Km/h)',\n       'Wind gust (Km/h)', 'Wind direction (Deg)']\n\n    # construct and train pipeline\n    time = utils.IndexSelector()\n    weather = utils.WeatherComponents(cols)\n    union = FeatureUnion([('indices', time), ('weather' weather)])\n    poly = PolynomialFeatures()\n    scaler = StandardScaler()\n    svr = SVR(gamma='auto')\n\n    pipe1 = Pipeline([('union', union)])\n    df_train = pipe1.transform(df_train)\n    pipe2 = Pipeline([('drift', poly),\n                    ('scaler', scaler),\n                    ('regressor', svr)],memory=cachedir)\n    param_grid = {\"drift__degree\": range(2,4),\n                    \"regressor__degree\":range(2,4),\n                    \"regressor__kernel\":('rbf','poly','sigmoid'),\n                    \"regressor__C\": np.linspace(1,50,10), #>0\n                    \"regressor__tol\":np.logspace(-4,1,10),\n                    \"regressor__epsilon\":np.linspace(0.1,1.1,5)\n                    }\n    ts_cv = TimeSeriesSplit(5) # 5-fold forward chaining\n    search = GridSearchCV(\n        pipe2, param_grid, cv=ts_cv, scoring = 'r2', verbose=1)\n    utils.logger(\"Performing grid search...\")\n    search.fit(df_train, y_train)\n    utils.logger(\"Best score: %0.3f\" % search.best_score_)\n    utils.logger(\"Best parameters set:\")\n    best_parameters = search.best_estimator_.get_params()\n    for param_name in sorted(param_grid.keys()):\n        utils.logger(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n\n    utils.logger.info(\"Saving model...\")\n    joblib.dump(search, 'GridSearch.pckl')\n        \nif __name__ == '__main__':\n    main()"}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}